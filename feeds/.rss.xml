<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>guozhongxin's blog</title><link>http://www.guozhongxin.com/</link><description></description><atom:link href="http://www.guozhongxin.com/feeds/.rss.xml" rel="self"></atom:link><lastBuildDate>Tue, 25 Apr 2017 23:00:00 +0800</lastBuildDate><item><title>重新开始使用这个博客</title><link>http://www.guozhongxin.com/pages/2017/04/25/restart.html</link><description>&lt;h2&gt;关于此博客&lt;/h2&gt;
&lt;p&gt;这个博客刚开始搭建时，我刚上研究生不久。那时我对于各种技术都很懵懂，又充满热情。搭建博客之初，我还计划着把我的成长都记录在这，因此，对这个博客也充满热情。&lt;/p&gt;
&lt;p&gt;早在2013年底，当时大四的我有幸进入了IBM中国研究院，前后做了接近一年的实习生。正是这段经历，我开始接触并学习分布式平台，特别要感谢我的mentor，巨伟，给还是小白的我提供了很多帮助和指导，让我在知识之外学习到研究的基本方法。&lt;/p&gt;
&lt;p&gt;那时“大数据”的概念刚开始炒作，Hadoop已经推广开来，Spark方兴未艾，我也把分布式技术作为我读研期间的主要方向。当时就想着，把我在学习过程中的收获和体会都记录在这，积少成多，一定是一个值得期待的事情。&lt;/p&gt;
&lt;p&gt;但是在写了几篇文章后，这种热情就削减了。可能是我之前对自己、对这个博客期望太高了，写出来的东西并不满意，平常忙(hao)于(chi)学(lan)业(zuo)，没能持续投入精力去维护这个博客。特别是看到一些大牛的blog，自己的文章更是相形见绌，也没啥新意。最后导致了这个博客荒废了两年零三个月。&lt;/p&gt;
&lt;h2&gt;博客荒废之后的我&lt;/h2&gt;
&lt;p&gt;其实，博客荒废的这两年多，是我快速成长、变化的阶段。更具体的来说，我完成了研究生学业，并开始了职业生涯。这两年多也是我经历最丰富的阶段。&lt;/p&gt;
&lt;h3&gt;· 2015&lt;/h3&gt;
&lt;p&gt;2015年全年的时间基本都是在实验室做项目，也开始慢慢蹭蹭的做些研究，找论文点。主要的工作一方面是在搞一些机器学习算法的分布式实现上，一方面是在做一些实验室分布式集群的完善和性能调优上，这个阶段，经历Spark从1.2到1.5.2（刚才特地去官网上验证了一下，证明我的记忆没有偏差），社区越来越活跃，周边项目逐渐丰富起来。实验室的数据分析工作基本上都跑在Spark上，MLlib和GraphX的逐渐丰富提供了很大的帮助。&lt;/p&gt;
&lt;p&gt;从2014年底开始接触股票的我，在小赚一笔后迎来了15年的“股灾”，不仅金钱损失，也耗费了不少时间和精力。现在虽未完全退市，但基本不投入精力了，一个月操作不了几次。&lt;/p&gt;
&lt;h3&gt;· 2016&lt;/h3&gt;
&lt;h4&gt;·· 实习：和MSRA的第一段缘分&lt;/h4&gt;
&lt;p&gt;进入2016年后，日子就没有那么轻松了。一方面小论文不能再拖了，一方面要开始找实习，准备找工作了。春节前学长内推我去微软亚洲研究院实习。面试的组正在做分布式计算的相关研究，要基于Spark源码做开发，面试的内容主要和Spark相关。当时面试官，也是后来的同事chenyang、gaoyanjie，拿了一个笔记本过来，直接对着Spark源码开始提问。整体上面试内容正合我胃口，也就有幸拿到了MSRA的实习机会。&lt;/p&gt;
&lt;p&gt;在MSRA的前半段时间里，我参与到了TR-Spark的工作中来。简单来说，TR-Spark是在一种非常不稳定的云环境（&lt;code&gt;Transient Resource&lt;/code&gt;）下，依然能稳定工作的分布式计算平台，是当时的代码在Spark 1.5.2版本上进行二次开发的。这种不稳定的云环境是一些非常廉价的云主机，会在其他租户申请资源时被主动释放掉，以供这些“高级”租户使用，虽然不稳定，但也相当廉价。TR-Spark在这种环境下，通过resource stability and data size reduction-aware scheduling，以及 lineage-aware checkpointing两大策略相结合，智能的备份Spark计算的中间结果（两个Stage之间进行shuffle时的&lt;code&gt;block&lt;/code&gt;），从而提高了分布式平台在Transient Resource环境下的高可用性[1]。&lt;/p&gt;
&lt;p&gt;之后，我的mentor，yanying转向了区块链&lt;code&gt;BlockChain&lt;/code&gt;的研究。我还记得的最开始的时候，ying姐拉我到一个讨论室里“安利”我什么是BlockChain，这是我第一次听说这个技术，听得我云里雾里。紧接着，ying姐，chenyang带着我开始看各种相关BlockChain开源项目的白皮书，开始研究BlockChain到底是什么。刚接触新事物的我会比较迷茫，不知道从何看起，而且有时会get不到两位researcher的点。在ying姐的强有力的指导和push下，我们抽丝剥茧，一步步理解BlockChain技术核心。实际中我们是从BigchainDB源码开始，了解BlockChain运作的整个流程。并基于BigchainDB做了一个基于BlockChain的慈善系统（BlockChain for Charity），参加了微软的Hackathon。由于在不像大多数BlockChain上都是虚拟货币，在慈善系统中记录的可能是实际货币，甚至是物品，因此我在BigchainDB上做了一个tx receiver要进行确认的机制。在这个项目中，我们也发现BigchainDB的整体架构和主流的区块链项目有明显差异：BigchainDB是建立在一个分布式的数据库上，而不是各自节点分别maintain一个数据库，因此虽然不用考虑数据一致性的问题从而提高了Throughput，但是也给整个系统带来了安全上的风险。这一差异各有优劣。之后我们又开始研究Ethereum，一个主流的BlockChain项目，我重点关注了Smart Contract方面的问题。&lt;/p&gt;
&lt;p&gt;从16年2月底到9月初，六个月多的时间过得很快，也很充实。最幸运的是有一个超级棒的mentor，在各个方面给我很多指导和机会，自己受益匪浅。实习期间合作的两位同事，Spark专家yanjie，博学的chenyang，还有老板Thomas，也都让我对MSRA充满了崇拜。&lt;/p&gt;
&lt;h4&gt;·· 小论文：一波两折&lt;/h4&gt;
&lt;p&gt;到了16年我的小论文不能再拖了，春节期间把论文思路整理里一下，研二下学期开学回来就开始动笔了。&lt;/p&gt;
&lt;p&gt;小论文主要研究内容是针对分布式计算平台的性能瓶颈进行分析、建模。所谓性能瓶颈主要是指分布式作业执行期间，集群资源的有限性对执行效率的影响。最初的点是IBM研究院实现时的mentor，巨伟提出的，我零零散散做了近一年的时间。首先是将性能瓶颈进行量化，把性能分析从定性分析问题变成量化指标。再通过计算平台log中的metrics对性能瓶颈指标进行建模，得到一个适用于不同集群、不同类型作业的性能瓶颈模型。&lt;/p&gt;
&lt;p&gt;在小论文上，主要从一个和我自己导师有合作关系的老师那里得到了一些指导，但她对研究内容本身没有太多了解。第一版的论文写得很潦草，投了CIKM，等了两个月之后最后收到了4个review，两个accept、一个borderline、一个reject，最后得到chair的reject。一般cikm都是3个reviewer，看来在最开始的review中分歧较大，多加了一个。这些review很犀利，也很到位，不得不服。&lt;/p&gt;
&lt;p&gt;在做了相对应的修改和调整后，我和导师就投稿会议产生了分歧，导师想让我投VLDB这样的顶会，我不思进取找个时间近的水会就要投，最后导师还是放了我一马，投了HPCC: 。在修改论文时，我在MSRA实习的两位小伙伴youer和辰哥帮我修改英文表达，事实证明留学的博士就是强。感觉在MSRA认识的博士都非常让我佩服，洗刷了我对博士的naive的偏见，也后悔当时怎么没考虑读博呢。。&lt;/p&gt;
&lt;h4&gt;·· 找工作：兜兜转转回到起点&lt;/h4&gt;
&lt;h6&gt;【太晚了，未完待续。。。】&lt;/h6&gt;
&lt;p&gt;p.s. 坚决不能烂尾&lt;/p&gt;
&lt;p&gt;[1]Yan Y, Gao Y, Chen Y, et al. TR-Spark: Transient Computing for Big Data Analytics[C]// ACM Symposium on Cloud Computing(SoCC). ACM, 2016:484-496.&lt;/p&gt;
&lt;p&gt;[2]Guo Z, Hu Z, Zhang C, et al. Learning-Based Characterizing and Modeling Performance Bottlenecks of Big Data Workloads[C]//IEEE 18th International Conference on High Performance Computing and Communications(HPCC). IEEE, 2016: 860-867.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">guozhongxin</dc:creator><pubDate>Tue, 25 Apr 2017 23:00:00 +0800</pubDate><guid>tag:www.guozhongxin.com,2017-04-25:pages/2017/04/25/restart.html</guid></item></channel></rss>